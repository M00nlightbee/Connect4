{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0310137e",
   "metadata": {},
   "source": [
    "# <font color= \"magenta\">  ****Explore Data.****</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa179c32",
   "metadata": {},
   "source": [
    "**1. Import required libraries.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0d29fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from Terminal_Version.Connect4 import Connect4\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import (\n",
    "    StandardScaler,\n",
    "    MinMaxScaler,\n",
    "    MaxAbsScaler,\n",
    "    RobustScaler,\n",
    "    QuantileTransformer,\n",
    "    PowerTransformer,\n",
    ")\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34448c9",
   "metadata": {},
   "source": [
    "**2. Create game moves function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "576b3262",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_game_moves(flat_board):\n",
    "    board = np.array(flat_board).reshape(6, 7)\n",
    "    moves = []\n",
    "    for col in range(7):\n",
    "        col_vals = board[:, col]\n",
    "        pieces = [val for val in col_vals if val != 0]\n",
    "        for _ in pieces:\n",
    "            moves.append(col)\n",
    "    return moves"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3d6620",
   "metadata": {},
   "source": [
    "**3. Data preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d9af589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_set_prep():\n",
    "    columns = [f'b.{i}' for i in range(42)] + ['outcome']\n",
    "    df = pd.read_csv(r'Data\\connect-4.data\\connect-4.data', names=columns)\n",
    "\n",
    "    mapping = {'x': 1, 'o': -1, 'b': 0}\n",
    "    df.iloc[:, :-1] = df.iloc[:, :-1].map(mapping.get)\n",
    "\n",
    "    X_data = []\n",
    "    y_data = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        board_vals = row[:-1].values\n",
    "        move_sequence = convert_to_game_moves(board_vals)\n",
    "        game = Connect4()\n",
    "        player_map = {1: \"●\", -1: \"○\"}\n",
    "        player_turns = [1 if i % 2 == 0 else -1 for i in range(len(move_sequence))]\n",
    "\n",
    "        for i, (move, player_id) in enumerate(zip(move_sequence[:-1], player_turns[:-1])):\n",
    "            flat_numeric_board = np.where(game.board == \"●\", 1,\n",
    "                                  np.where(game.board == \"○\", -1, 0)).flatten()\n",
    "            turn_count = np.count_nonzero(flat_numeric_board)\n",
    "            X_data.append(np.append(flat_numeric_board, turn_count))\n",
    "            y_data.append(move_sequence[i + 1])  # Next move is the target\n",
    "            game.make_move(move, player_map[player_id])\n",
    "\n",
    "    X_data = np.array(X_data)\n",
    "    y_data = np.array(y_data)\n",
    "\n",
    "    print(\"Dataset built:\")\n",
    "    print(f\"Total training samples: {X_data.shape[0]}\")\n",
    "    # print(\"Inferred move for that board:\", y_data[0])\n",
    "    return X_data, y_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f963ecaf",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5e22160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, y, model_type=SVC, scaler_type='standard', cv_folds=5, **model_kwargs):\n",
    "    # Select scaler\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'minmax':\n",
    "        scaler = MinMaxScaler()\n",
    "    elif scaler_type == 'maxabs':\n",
    "        scaler = MaxAbsScaler()\n",
    "    elif scaler_type == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    elif scaler_type == 'quantile':\n",
    "        scaler = QuantileTransformer(output_distribution='uniform')\n",
    "    elif scaler_type == 'quantile-normal':\n",
    "        scaler = QuantileTransformer(output_distribution='normal')\n",
    "    elif scaler_type == 'power':\n",
    "        scaler = PowerTransformer(method='yeo-johnson')\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported scaler_type: {scaler_type}\")\n",
    "\n",
    "    # Normalize features\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # Split for hold-out test evaluation\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=0.2, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    # Instantiate model\n",
    "    model = model_type(**model_kwargs)\n",
    "    print(f\"\\nTraining {model_type.__name__} with {scaler_type} scaler...\")\n",
    "\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=cv_folds)\n",
    "    print(f\"Cross-Validation (k={cv_folds}) Accuracy: {cv_scores.mean() * 100:.2f}% ± {cv_scores.std() * 100:.2f}%\")\n",
    "\n",
    "    # Final fit on full training set\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Hold-out test evaluation\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    report = classification_report(y_test, predictions, zero_division=0)\n",
    "\n",
    "    print(f\"Hold-out Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "    print(\"Classification Report:\\n\", report)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea710a8f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56aa033b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_move(board, model):\n",
    "    board_arr = np.array(board).reshape(1, -1)\n",
    "    predicted_move = int(round(model.predict(board_arr)[0]))\n",
    "    return max(0, min(6, predicted_move))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb28f1a6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc7e6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_move(game, model, player=1):\n",
    "    opponent = -player\n",
    "    player_map = {1: \"●\", -1: \"○\"}\n",
    "    opponent_symbol = player_map[opponent]\n",
    "    available_cols = game.get_available_moves(game.board)\n",
    "\n",
    "    # Check if the AI can block the opponent's winning move\n",
    "    for col in available_cols:\n",
    "        temp_board = game.drop_piece(game.board.copy(), col, opponent_symbol)\n",
    "        if temp_board is not None and game.check_winner(opponent_symbol, temp_board):\n",
    "            return col  # Block opponent's winning move\n",
    "\n",
    "    # Use the trained model to predict the next move\n",
    "    flat_board = np.where(game.board == \"●\", 1,\n",
    "                          np.where(game.board == \"○\", -1, 0)).flatten()\n",
    "    turn_count = np.count_nonzero(flat_board)\n",
    "    input_features = np.append(flat_board, turn_count)\n",
    "\n",
    "    # Predict the move using the trained model\n",
    "    predicted_move = predict_move(input_features, model)\n",
    "\n",
    "    # Ensure the predicted move is valid\n",
    "    if predicted_move in available_cols:\n",
    "        return predicted_move\n",
    "    else:\n",
    "        # Default to a random valid move if the prediction is invalid\n",
    "        return np.random.choice(available_cols) if available_cols else None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbddd47",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35650beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_game(model):\n",
    "    game = Connect4()\n",
    "    current_player = 1\n",
    "    player_map = {1: \"●\", -1: \"○\"}\n",
    "\n",
    "    while True:\n",
    "        game.display_board()\n",
    "        available_cols = game.get_available_moves(game.board)\n",
    "        print(f\"Available columns: {available_cols}\")\n",
    "\n",
    "        if current_player == 1:\n",
    "            # Human player move\n",
    "            while True:\n",
    "                try:\n",
    "                    col = int(input(\"Enter column (0-6): \"))\n",
    "                    if col in available_cols:\n",
    "                        game.make_move(col, player_map[current_player])\n",
    "                        break\n",
    "                    else:\n",
    "                        print(\"Column full or invalid.\")\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input.\")\n",
    "        else:\n",
    "            # AI move\n",
    "            print(\"AI's move:\")\n",
    "            col = choose_move(game, model, player=-1)\n",
    "            if col is not None:\n",
    "                print(f\"AI chooses column {col}\")\n",
    "                game.make_move(col, player_map[current_player])\n",
    "            else:\n",
    "                print(\"AI could not make a move!\")\n",
    "                break\n",
    "\n",
    "        if game.check_winner(\"○\"):\n",
    "            game.display_board()\n",
    "            print(\"AI wins!\")\n",
    "            break\n",
    "        elif game.check_winner(\"●\"):\n",
    "            game.display_board()\n",
    "            print(\"You win!\")\n",
    "            break\n",
    "        elif game.is_full(game.board):\n",
    "            game.display_board()\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "        # Switch player\n",
    "        current_player *= -1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d5c1f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7cb37ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset built:\n",
      "Total training samples: 472899\n",
      "\n",
      "--- Training with scaler: standard ---\n",
      "\n",
      "Training LogisticRegression with standard scaler...\n",
      "Cross-Validation (k=5) Accuracy: 55.54% ± 0.12%\n",
      "Hold-out Test Accuracy: 55.47%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.44      0.36      0.40     14691\n",
      "           3       0.44      0.17      0.24     12059\n",
      "           4       0.48      0.23      0.31     12735\n",
      "           5       0.50      0.75      0.60     16377\n",
      "           6       0.88      0.83      0.85     17642\n",
      "\n",
      "    accuracy                           0.55     94580\n",
      "   macro avg       0.46      0.47      0.44     94580\n",
      "weighted avg       0.52      0.55      0.51     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: minmax ---\n",
      "\n",
      "Training LogisticRegression with minmax scaler...\n",
      "Cross-Validation (k=5) Accuracy: 55.51% ± 0.11%\n",
      "Hold-out Test Accuracy: 55.45%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.44      0.36      0.40     14691\n",
      "           3       0.44      0.17      0.24     12059\n",
      "           4       0.48      0.23      0.31     12735\n",
      "           5       0.50      0.75      0.60     16377\n",
      "           6       0.88      0.82      0.85     17642\n",
      "\n",
      "    accuracy                           0.55     94580\n",
      "   macro avg       0.46      0.47      0.44     94580\n",
      "weighted avg       0.52      0.55      0.51     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: maxabs ---\n",
      "\n",
      "Training LogisticRegression with maxabs scaler...\n",
      "Cross-Validation (k=5) Accuracy: 55.53% ± 0.11%\n",
      "Hold-out Test Accuracy: 55.44%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.44      0.36      0.40     14691\n",
      "           3       0.44      0.17      0.24     12059\n",
      "           4       0.48      0.23      0.31     12735\n",
      "           5       0.50      0.75      0.60     16377\n",
      "           6       0.88      0.82      0.85     17642\n",
      "\n",
      "    accuracy                           0.55     94580\n",
      "   macro avg       0.46      0.47      0.44     94580\n",
      "weighted avg       0.52      0.55      0.51     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: robust ---\n",
      "\n",
      "Training LogisticRegression with robust scaler...\n",
      "Cross-Validation (k=5) Accuracy: 55.54% ± 0.11%\n",
      "Hold-out Test Accuracy: 55.49%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.44      0.36      0.40     14691\n",
      "           3       0.44      0.17      0.24     12059\n",
      "           4       0.48      0.23      0.31     12735\n",
      "           5       0.50      0.75      0.60     16377\n",
      "           6       0.88      0.83      0.85     17642\n",
      "\n",
      "    accuracy                           0.55     94580\n",
      "   macro avg       0.46      0.47      0.44     94580\n",
      "weighted avg       0.52      0.55      0.51     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: quantile ---\n",
      "\n",
      "Training LogisticRegression with quantile scaler...\n",
      "Cross-Validation (k=5) Accuracy: 55.47% ± 0.17%\n",
      "Hold-out Test Accuracy: 55.45%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.44      0.36      0.40     14691\n",
      "           3       0.43      0.17      0.24     12059\n",
      "           4       0.48      0.23      0.31     12735\n",
      "           5       0.50      0.75      0.60     16377\n",
      "           6       0.88      0.82      0.85     17642\n",
      "\n",
      "    accuracy                           0.55     94580\n",
      "   macro avg       0.46      0.47      0.44     94580\n",
      "weighted avg       0.52      0.55      0.51     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: quantile-normal ---\n",
      "\n",
      "Training LogisticRegression with quantile-normal scaler...\n",
      "Cross-Validation (k=5) Accuracy: 55.65% ± 0.10%\n",
      "Hold-out Test Accuracy: 55.59%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.44      0.36      0.40     14691\n",
      "           3       0.41      0.17      0.24     12059\n",
      "           4       0.46      0.21      0.29     12735\n",
      "           5       0.51      0.75      0.61     16377\n",
      "           6       0.88      0.84      0.86     17642\n",
      "\n",
      "    accuracy                           0.56     94580\n",
      "   macro avg       0.46      0.47      0.44     94580\n",
      "weighted avg       0.52      0.56      0.51     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: power ---\n",
      "\n",
      "Training LogisticRegression with power scaler...\n",
      "Cross-Validation (k=5) Accuracy: 56.18% ± 0.20%\n",
      "Hold-out Test Accuracy: 56.21%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.44      0.36      0.40     14691\n",
      "           3       0.43      0.17      0.24     12059\n",
      "           4       0.48      0.23      0.31     12735\n",
      "           5       0.52      0.74      0.61     16377\n",
      "           6       0.87      0.88      0.88     17642\n",
      "\n",
      "    accuracy                           0.56     94580\n",
      "   macro avg       0.46      0.48      0.44     94580\n",
      "weighted avg       0.52      0.56      0.51     94580\n",
      "\n",
      "\n",
      "All models trained with different scalers.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        X, y = data_set_prep()\n",
    "\n",
    "        model_choice = input(\"Choose model (logistic, forest, lsvc): \").strip().lower()\n",
    "\n",
    "        if model_choice == \"forest\":\n",
    "            model_type = RandomForestClassifier\n",
    "            model_kwargs = {\"n_estimators\": 1000}\n",
    "        elif model_choice == \"lsvc\":\n",
    "            from sklearn.svm import LinearSVC\n",
    "            model_type = LinearSVC\n",
    "            model_kwargs = {}\n",
    "        else:\n",
    "            model_type = LogisticRegression\n",
    "            model_kwargs = {\"max_iter\": 5000}\n",
    "\n",
    "        scaler_types = [\n",
    "            'standard',\n",
    "            'minmax',\n",
    "            'maxabs',\n",
    "            'robust',\n",
    "            'quantile',\n",
    "            'quantile-normal',\n",
    "            'power'\n",
    "        ]\n",
    "\n",
    "        for scaler_type in scaler_types:\n",
    "            print(f\"\\n--- Training with scaler: {scaler_type} ---\")\n",
    "            model = train_model(X, y, model_type=model_type, scaler_type=scaler_type, **model_kwargs)\n",
    "\n",
    "        print(\"\\nAll models trained with different scalers.\")\n",
    "        # play_game(model)  # This will use the *last* trained model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4576447a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f2680461",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset built:\n",
      "Total training samples: 472899\n",
      "\n",
      "--- Training with scaler: standard ---\n",
      "\n",
      "Training RandomForestClassifier with standard scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.27% ± 0.08%\n",
      "Hold-out Test Accuracy: 59.47%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.46      0.48      0.47     14691\n",
      "           3       0.47      0.30      0.37     12059\n",
      "           4       0.59      0.23      0.33     12735\n",
      "           5       0.64      0.73      0.68     16377\n",
      "           6       0.90      0.87      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.51      0.51      0.48     94580\n",
      "weighted avg       0.57      0.59      0.56     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: minmax ---\n",
      "\n",
      "Training RandomForestClassifier with minmax scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.27% ± 0.07%\n",
      "Hold-out Test Accuracy: 59.47%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.46      0.48      0.47     14691\n",
      "           3       0.47      0.30      0.37     12059\n",
      "           4       0.59      0.23      0.33     12735\n",
      "           5       0.64      0.73      0.68     16377\n",
      "           6       0.90      0.87      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.51      0.51      0.48     94580\n",
      "weighted avg       0.57      0.59      0.56     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: maxabs ---\n",
      "\n",
      "Training RandomForestClassifier with maxabs scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.27% ± 0.08%\n",
      "Hold-out Test Accuracy: 59.47%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.46      0.48      0.47     14691\n",
      "           3       0.47      0.30      0.37     12059\n",
      "           4       0.59      0.23      0.33     12735\n",
      "           5       0.64      0.73      0.68     16377\n",
      "           6       0.90      0.87      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.51      0.51      0.48     94580\n",
      "weighted avg       0.57      0.59      0.56     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: robust ---\n",
      "\n",
      "Training RandomForestClassifier with robust scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.27% ± 0.07%\n",
      "Hold-out Test Accuracy: 59.47%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.46      0.48      0.47     14691\n",
      "           3       0.47      0.30      0.37     12059\n",
      "           4       0.59      0.23      0.33     12735\n",
      "           5       0.64      0.73      0.68     16377\n",
      "           6       0.90      0.87      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.51      0.51      0.48     94580\n",
      "weighted avg       0.57      0.59      0.56     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: quantile ---\n",
      "\n",
      "Training RandomForestClassifier with quantile scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.27% ± 0.08%\n",
      "Hold-out Test Accuracy: 59.47%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.46      0.48      0.47     14691\n",
      "           3       0.47      0.30      0.37     12059\n",
      "           4       0.59      0.23      0.33     12735\n",
      "           5       0.64      0.73      0.68     16377\n",
      "           6       0.90      0.87      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.51      0.51      0.48     94580\n",
      "weighted avg       0.57      0.59      0.56     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: quantile-normal ---\n",
      "\n",
      "Training RandomForestClassifier with quantile-normal scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.27% ± 0.08%\n",
      "Hold-out Test Accuracy: 59.47%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.46      0.48      0.47     14691\n",
      "           3       0.47      0.30      0.37     12059\n",
      "           4       0.59      0.23      0.33     12735\n",
      "           5       0.64      0.73      0.68     16377\n",
      "           6       0.90      0.87      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.51      0.51      0.48     94580\n",
      "weighted avg       0.57      0.59      0.56     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: power ---\n",
      "\n",
      "Training RandomForestClassifier with power scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.27% ± 0.07%\n",
      "Hold-out Test Accuracy: 59.47%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.46      0.48      0.47     14691\n",
      "           3       0.47      0.30      0.37     12059\n",
      "           4       0.59      0.23      0.33     12735\n",
      "           5       0.64      0.73      0.68     16377\n",
      "           6       0.90      0.87      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.51      0.51      0.48     94580\n",
      "weighted avg       0.57      0.59      0.56     94580\n",
      "\n",
      "\n",
      "All models trained with different scalers.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        X, y = data_set_prep()\n",
    "\n",
    "        model_choice = input(\"Choose model (logistic, forest, lsvc): \").strip().lower()\n",
    "\n",
    "        if model_choice == \"forest\":\n",
    "            model_type = RandomForestClassifier\n",
    "            model_kwargs = {\"n_estimators\": 1000}\n",
    "        elif model_choice == \"lsvc\":\n",
    "            from sklearn.svm import LinearSVC\n",
    "            model_type = LinearSVC\n",
    "            model_kwargs = {}\n",
    "        else:\n",
    "            model_type = LogisticRegression\n",
    "            model_kwargs = {\"max_iter\": 5000}\n",
    "\n",
    "        scaler_types = [\n",
    "            'standard',\n",
    "            'minmax',\n",
    "            'maxabs',\n",
    "            'robust',\n",
    "            'quantile',\n",
    "            'quantile-normal',\n",
    "            'power'\n",
    "        ]\n",
    "\n",
    "        for scaler_type in scaler_types:\n",
    "            print(f\"\\n--- Training with scaler: {scaler_type} ---\")\n",
    "            model = train_model(X, y, model_type=model_type, scaler_type=scaler_type, **model_kwargs)\n",
    "\n",
    "        print(\"\\nAll models trained with different scalers.\")\n",
    "        # play_game(model)  # This will use the *last* trained model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56da4ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset built:\n",
      "Total training samples: 472899\n",
      "\n",
      "--- Training with scaler: standard ---\n",
      "\n",
      "Training MLPClassifier with standard scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.27% ± 0.07%\n",
      "Hold-out Test Accuracy: 59.18%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.48      0.44      0.46     14691\n",
      "           3       0.47      0.19      0.27     12059\n",
      "           4       0.53      0.34      0.42     12735\n",
      "           5       0.60      0.76      0.67     16377\n",
      "           6       0.91      0.85      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.50      0.51      0.48     94580\n",
      "weighted avg       0.56      0.59      0.55     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: power ---\n",
      "\n",
      "Training MLPClassifier with power scaler...\n",
      "Cross-Validation (k=5) Accuracy: 59.17% ± 0.12%\n",
      "Hold-out Test Accuracy: 59.35%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.46      0.48      0.47     14691\n",
      "           3       0.47      0.17      0.25     12059\n",
      "           4       0.53      0.34      0.42     12735\n",
      "           5       0.64      0.73      0.68     16377\n",
      "           6       0.90      0.87      0.88     17642\n",
      "\n",
      "    accuracy                           0.59     94580\n",
      "   macro avg       0.50      0.51      0.48     94580\n",
      "weighted avg       0.56      0.59      0.55     94580\n",
      "\n",
      "\n",
      "All models trained with different scalers.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        X, y = data_set_prep()\n",
    "\n",
    "        model_choice = input(\"Choose model (logistic, forest, lsvc): \").strip().lower()\n",
    "\n",
    "        if model_choice == \"forest\":\n",
    "            model_type = RandomForestClassifier\n",
    "            model_kwargs = {\"n_estimators\": 1000}\n",
    "        elif model_choice == \"lsvc\":\n",
    "            from sklearn.svm import LinearSVC\n",
    "            model_type = LinearSVC\n",
    "            model_kwargs = {}\n",
    "        elif model_choice == \"mlp\":\n",
    "            from sklearn.neural_network import MLPClassifier\n",
    "            model_type = MLPClassifier\n",
    "            model_kwargs = {}      \n",
    "        else:\n",
    "            model_type = LogisticRegression\n",
    "            model_kwargs = {\"max_iter\": 5000}\n",
    "\n",
    "        scaler_types = [\n",
    "            'standard',\n",
    "            'power'\n",
    "        ]\n",
    "\n",
    "        for scaler_type in scaler_types:\n",
    "            print(f\"\\n--- Training with scaler: {scaler_type} ---\")\n",
    "            model = train_model(X, y, model_type=model_type, scaler_type=scaler_type, **model_kwargs)\n",
    "\n",
    "        print(\"\\nAll models trained with different scalers.\")\n",
    "        # play_game(model)  # This will use the *last* trained model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "04eb8fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset built:\n",
      "Total training samples: 472899\n",
      "\n",
      "--- Training with scaler: standard ---\n",
      "\n",
      "Training LinearSVC with standard scaler...\n",
      "Cross-Validation (k=5) Accuracy: 50.11% ± 0.14%\n",
      "Hold-out Test Accuracy: 50.13%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.43      0.36      0.40     14691\n",
      "           3       0.34      0.07      0.12     12059\n",
      "           4       0.11      0.01      0.02     12735\n",
      "           5       0.40      0.71      0.51     16377\n",
      "           6       0.77      0.80      0.78     17642\n",
      "\n",
      "    accuracy                           0.50     94580\n",
      "   macro avg       0.36      0.42      0.36     94580\n",
      "weighted avg       0.42      0.50      0.42     94580\n",
      "\n",
      "\n",
      "--- Training with scaler: power ---\n",
      "\n",
      "Training LinearSVC with power scaler...\n",
      "Cross-Validation (k=5) Accuracy: 50.23% ± 0.08%\n",
      "Hold-out Test Accuracy: 50.30%\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00      5437\n",
      "           1       0.50      0.98      0.66     15639\n",
      "           2       0.43      0.36      0.40     14691\n",
      "           3       0.35      0.07      0.12     12059\n",
      "           4       0.13      0.01      0.03     12735\n",
      "           5       0.39      0.63      0.49     16377\n",
      "           6       0.72      0.88      0.79     17642\n",
      "\n",
      "    accuracy                           0.50     94580\n",
      "   macro avg       0.36      0.42      0.35     94580\n",
      "weighted avg       0.42      0.50      0.42     94580\n",
      "\n",
      "\n",
      "All models trained with different scalers.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        X, y = data_set_prep()\n",
    "\n",
    "        model_choice = input(\"Choose model (logistic, forest, lsvc): \").strip().lower()\n",
    "\n",
    "        if model_choice == \"forest\":\n",
    "            model_type = RandomForestClassifier\n",
    "            model_kwargs = {\"n_estimators\": 1000}\n",
    "        elif model_choice == \"lsvc\":\n",
    "            from sklearn.svm import LinearSVC\n",
    "            model_type = LinearSVC\n",
    "            model_kwargs = {}\n",
    "        elif model_choice == \"mlp\":\n",
    "            from sklearn.neural_network import MLPClassifier\n",
    "            model_type = MLPClassifier\n",
    "            model_kwargs = {}      \n",
    "        else:\n",
    "            model_type = LogisticRegression\n",
    "            model_kwargs = {\"max_iter\": 5000}\n",
    "\n",
    "        scaler_types = [\n",
    "            'standard',\n",
    "            'power'\n",
    "        ]\n",
    "\n",
    "        for scaler_type in scaler_types:\n",
    "            print(f\"\\n--- Training with scaler: {scaler_type} ---\")\n",
    "            model = train_model(X, y, model_type=model_type, scaler_type=scaler_type, **model_kwargs)\n",
    "\n",
    "        print(\"\\nAll models trained with different scalers.\")\n",
    "        # play_game(model)  # This will use the *last* trained model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
